# -*- coding: utf-8 -*-
"""ML assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yqdGUzuoA9YKfjawqxnJJYuz2ARmEAnO
"""

import pandas as pd
import numpy as np

df = pd.read_excel('/content/dummy_npi_data.xlsx')
df.head(5)

df['Login Time'] = df['Login Time'].dt.hour * 60 + df['Login Time'].dt.minute
df['Logout Time'] = df['Logout Time'].dt.hour * 60 + df['Logout Time'].dt.minute
df.head(5)

expanded_data = []
for _, row in df.iterrows():
    for interval in range(0, 1440, 15):
        active_label = 1 if row['Login Time'] <= interval < row['Logout Time'] else 0
        expanded_data.append({
            'NPI': row['NPI'],
            'State': row['State'],
            'Interval of Interest': interval,
            'Region': row['Region'],
            'Speciality': row['Speciality'],
            'Count of Survey Attempts': row['Count of Survey Attempts'],
            'Active': active_label
        })

expanded_df = pd.DataFrame(expanded_data)
expanded_df.head(5)

!pip install scikit-learn

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report


# Initialize encoder
encoder = LabelEncoder()

# Encode the 'Region' column
expanded_df['Region_Encoded'] = encoder.fit_transform(expanded_df['Region'])
expanded_df['State_Encoded'] = encoder.fit_transform(expanded_df['State'])
expanded_df['Speciality_Encoded'] = encoder.fit_transform(expanded_df['Speciality'])

df['Region_Encoded'] = encoder.fit_transform(df['Region'])
df['State_Encoded'] = encoder.fit_transform(df['State'])
df['Speciality_Encoded'] = encoder.fit_transform(df['Speciality'])

# Features and Target
features = ['NPI', 'State_Encoded', 'Region_Encoded', 'Speciality_Encoded', 'Count of Survey Attempts', 'Interval of Interest']
X = expanded_df[features]
y = expanded_df['Active']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train the model
model = RandomForestClassifier()
model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

from sklearn.metrics import precision_recall_curve

# Probability estimates
probas = model.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, probas)

# Optimising threshold by maximising F1 score
optimal_threshold = thresholds[np.argmax(2 * (precision * recall) / (precision + recall))]


print(f"Optimal Threshold for Recall â‰¥ 0.75: {optimal_threshold}")


# Predict with adjusted threshold
y_pred_adjusted = (probas >= optimal_threshold).astype(int)

print(f"\nMetrics after optimising threshold:")
accuracy = accuracy_score(y_test, y_pred_adjusted)
precision = precision_score(y_test, y_pred_adjusted)
recall = recall_score(y_test, y_pred_adjusted)
f1 = f1_score(y_test, y_pred_adjusted)

print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, auc

# `y_test` contains true labels and `probas` contains predicted probabilities
precision, recall, thresholds = precision_recall_curve(y_test, probas)

# Calculate AUC for reference
pr_auc = auc(recall, precision)

# Plotting
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.2f})', color='blue')
plt.axhline(y=0.75, color='red', linestyle='--', label='Target Recall = 0.75')
plt.title('Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend()
plt.grid(True)
plt.show()

# Taking input for prediction
time_input = input("Enter time in 24-hour format (HH:MM): ")

# Converting to minutes from midnight
hours, minutes = map(int, time_input.split(':'))
total_minutes = hours * 60 + minutes

# Adding the input to test dataframe
Interval = [total_minutes]*1000
df['Interval of Interest'] = Interval

# Predict for each doctor
targeted_doctors = []
test_data = df[['NPI', 'State_Encoded', 'Region_Encoded', 'Speciality_Encoded', 'Count of Survey Attempts', 'Interval of Interest']]

output = model.predict(test_data)

# Finding NPI from model output
count = 0
for i in range(1000):
  if output[i]:
    count+=1
    print(df['NPI'][i])
print(f"Number of doctors estimated to attempt survey at {time_input} is {count}")